# coding: utf-8
"""Accelerating Program Analyzers by Unleashing of Power of Compiler Optimizations
(Can run in parallel)

"""

import logging
import os
import signal
# import random
import sys
from multiprocessing.pool import Pool
from typing import List

from opt4spa.config import opt_bin, m_tool, opt_options
from opt4spa.gaopt import GA
from opt4spa.params import Params
from opt4spa.utils import run_cmd, get_unique_id, is_bc_or_ll_file

m_logging = logging.getLogger(__name__)

# Some configurations for this script
g_strategy = "random"
g_opt_timeout = 600
g_analyzer_timeout = 600
g_iterations = 3
g_is_parallel = False
g_default_time = 0


# End of configurations


def run_opt(in_name: str, out_name: str, extra_args: List) -> str:
    """Run llvm opt (for transforming and optimizing bitcode)"""
    assert out_name is not None
    try:
        opt_cmd = [opt_bin, '-f']
        opt_cmd.extend(['-o', out_name])
        if len(extra_args) > 0: opt_cmd.extend(extra_args)
        opt_cmd.append(in_name)
        # logging.debug(opt_cmd)
        duration = run_cmd(opt_cmd, g_opt_timeout)
        if duration >= float(g_opt_timeout):
            return "opt timeout"
        return " ".join(opt_cmd)
    except Exception as ex:
        print(ex)
        return "opt error"


def run_analyzer(bc: str) -> float:
    """Run the program analyzer (e.g., SVF)"""
    # global g_analyzer_timeout
    try:
        cmd_tool = [i for i in m_tool]
        cmd_tool.append(bc)
        logging.debug(cmd_tool)
        # logging.debug(" start to analyze")
        duration = run_cmd(cmd_tool, g_analyzer_timeout)
        # logging.debug("analysis time: \n", duration)
        if duration >= g_analyzer_timeout:
            return 4294967295.0
        return duration
    except Exception as ex:
        print(ex)
        return 4294967295.0


def def_opt_name(name: str, wd=None) -> str:
    """Get a new name for bc"""
    base = os.path.basename(name)
    if wd is None:
        wd = os.path.dirname(name)
    file_name = os.path.splitext(base)[0] + str(get_unique_id()) + '.o.bc'
    return os.path.join(wd, file_name)


def init_run(bc: str):
    """Run the initial bitcode (without any transformation)"""
    global g_default_time
    g_default_time = run_analyzer(bc)


def clear_tmp_files(bc_name: str):
    """Clear the tmp files generated by the wpa or dvf tool of SVF"""
    if os.path.isfile(bc_name):
        os.remove(bc_name)
        # remove .wpa file generated by SVF
    wpa_filename = os.path.splitext(bc_name)[0] + ".wpa"  # the exhaustive pointer analysis in SVF
    dvf_filename = os.path.splitext(bc_name)[0] + ".dvf"  # the demand-driven pointer analysis in SVF
    if os.path.isfile(wpa_filename): os.remove(wpa_filename)
    if os.path.isfile(dvf_filename): os.remove(dvf_filename)


def ga_optimize(bc: str):
    """Run Genetic algorithm to optimize the bitcode
       Currently, the GA is sequential, but can run different independent GA in parallel
    """
    # global g_iterations
    minimum_time = g_default_time
    minimum_opt = "init"

    def _ga_callback(para: Params) -> float:
        """for evaluating the fitness function"""
        new_bc_name = def_opt_name(bc, "/tmp/")
        try:
            extra_args = para.to_llvm_opt_args()
            opt_cmd_name = run_opt(bc, new_bc_name, extra_args)
            if os.path.isfile(new_bc_name) and not (opt_cmd_name == "opt error" or opt_cmd_name == "opt timeout"):
                time_new_bc = run_analyzer(new_bc_name)
                clear_tmp_files(new_bc_name)
                return time_new_bc
            return 4294967295.0
        except Exception as ee:
            print(ee)
            return 4294967295.0

    try:
        ga = GA(opt_options)
        for i in range(g_iterations):
            ga.evaluate(callback=_ga_callback)
            ga.repopulate()
            m_logging.info("finish {}-th iteration of GA...".format(i))
        minimum_time, minimum_opt = ga.retained()
    except Exception as ex:
        print(ex)

    return minimum_time, minimum_opt


def random_optimize(bc: str):
    """Use random sampling/mutations to optimize the bitcode
       Different samplers can run in parallel
    """
    minimum_time = g_default_time
    minimum_opt = "init"
    for _ in range(g_iterations):
        new_bc_name = def_opt_name(bc, "/tmp/")
        try:
            # randomly generate options
            para = Params()
            para.load(opt_options)
            para.mutate()
            extra_args = para.to_llvm_opt_args()

            opt_cmd_name = run_opt(bc, new_bc_name, extra_args)
            if os.path.isfile(new_bc_name) and not (opt_cmd_name == "opt error" or opt_cmd_name == "opt timeout"):
                logging.debug("finish generating new bc")
                time_new_bc = run_analyzer(new_bc_name)
                logging.debug("finish analyzing new bc")
                logging.debug("------------------------")

                if time_new_bc <= minimum_time:
                    minimum_time = time_new_bc
                    minimum_opt = opt_cmd_name

                clear_tmp_files(new_bc_name)

        except Exception as ex:
            print(ex)
            clear_tmp_files(new_bc_name)

    return minimum_time, minimum_opt


def optimize(bc: str):
    """
    Choose a compiler optimization strategy for bc
    """
    # global g_iterations
    if g_strategy == "random":
        return random_optimize(bc)
    elif g_strategy == "ga":
        return ga_optimize(bc)
    else:
        return random_optimize(bc)
    # signal.alarm(signal.SIGTERM)


# this is the global Pool (workers)
g_pool = None


def signal_handler(sig, frame):
    global g_pool
    if g_pool:
        g_pool.terminate()
    print("We are finish here, have a good day!")
    os.system("kill -9 wpa")  # this is ugly
    os.system("kill -9 opt")  # this is ugly
    os.system("rm /tmp/*.bc")  # this is ugly
    sys.exit(0)


def parallel_optimize(bc: str, m_num_process=10):
    # TODO: is this correct?
    global g_pool

    # Process the initial bitcode
    init_run(bc)
    m_logging.info("Finish the first run!!")
    m_logging.info("Default time: {}".format(g_default_time))
    if g_default_time >= g_analyzer_timeout:
        print("Default run timeout. Please set a longer timeout via --analyzer_timeout!")
        exit(0)
    m_logging.info("Start to optimize the parameters")

    g_pool = Pool(m_num_process)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGQUIT, signal_handler)
    signal.signal(signal.SIGHUP, signal_handler)

    results = []
    for _ in range(0, m_num_process):
        result = g_pool.apply_async(optimize, args=(bc,))
        results.append(result)
    g_pool.close()
    g_pool.join()

    time_data = []
    opt_data = []
    for result in results:
        time_data.append(result.get()[0])
        opt_data.append(result.get()[1])

    # print(time_data)
    # print(opt_data)
    m_time = min(time_data)
    m_opt = opt_data[time_data.index(min(time_data))]
    m_logging.info("minimum time: {}".format(m_time))
    m_logging.info("opt: {}".format(m_opt))

    return m_time, m_opt


def sequential_optimize(bc: str):
    logging.debug("run sequential optimizer")

    init_run(bc)
    m_logging.info("Finish the first run, time: {}".format(g_default_time))
    if g_default_time >= g_analyzer_timeout:
        print("Default run timeout!")
        exit(0)
    m_logging.info("Start to optimize")

    def seq_signal_handler(sig, frame):
        print("We are finish here, have a good day!")
        os.system("kill -9 wpa") # wpa is an entrance of SVF
        os.system("kill -9 opt") # opt is from LLVM
        os.system("rm /tmp/*.bc")
        sys.exit(0)

    signal.signal(signal.SIGINT, seq_signal_handler)
    signal.signal(signal.SIGTERM, seq_signal_handler)
    signal.signal(signal.SIGQUIT, seq_signal_handler)
    signal.signal(signal.SIGHUP, seq_signal_handler)

    m_time, m_opt = optimize(bc)
    m_logging.info("minimum time: {}".format(m_time))
    m_logging.info("opt: {}".format(m_opt))

    return m_time, m_opt


if __name__ == "__main__":
    # g_strategy, g_opt_timeout, g_analyzer_timeout, g_iterations, g_is_parallel
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--workers', dest='workers', default=1, type=int, help="num threads")
    parser.add_argument('--opt_timeout', dest='opt_timeout', default=600, type=int,
                        help="timeout of opt")
    parser.add_argument('--analyzer_timeout', dest='analyzer_timeout', default=600, type=int,
                        help="timeout of the analyzer")
    parser.add_argument('--iterations', dest='iterations', default=6, type=int,
                        help="number of iterations for the opt")
    parser.add_argument('--strategy', dest='strategy', default='random', type=str)
    parser.add_argument("-v", "--verbose", help="increase output verbosity",
                        action="store_true")

    parser.add_argument("infile", type=str, help="Path to input filed")

    args = parser.parse_args()
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    m_input_file = args.infile
    if not (os.path.isfile(m_input_file) and is_bc_or_ll_file(m_input_file)):
        print("Input file is not a bitcode!")
        exit(0)

    # initialize global variables
    g_strategy = args.strategy
    g_opt_timeout = args.opt_timeout
    g_analyzer_timeout = args.analyzer_timeout
    g_iterations = args.iterations

    if args.workers > 1:
        g_is_parallel = True
        min_time, min_opt = parallel_optimize(m_input_file, args.workers)
    else:
        min_time, min_opt = sequential_optimize(m_input_file)

    m_logging.info("Writing result to file...")
    output_filename = "{0}-{1}-{2}-iterations.txt".format(os.path.basename(m_input_file), g_strategy, g_iterations)
    with open(output_filename, "w") as file:
        file.write("{}\n".format(m_input_file))
        file.write("default time: {}\n".format(g_default_time))
        file.write("min time: {}\n".format(min_time))
        file.write("min opt: {}\n".format(min_opt))
        file.close()
    m_logging.info("Good bye!")
